"""
Production-Ready Fast NLP Classifier
Optimized for speed and accuracy with proper error handling.
"""

import time
import logging
from typing import Tuple, List
import os

logger = logging.getLogger(__name__)

# Global model cache
_classifier = None
_model_loading_time = None

try:
    from transformers import pipeline
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    logger.warning("transformers not available. Using enhanced keyword classification.")
    TRANSFORMERS_AVAILABLE = False


def get_fast_classifier():
    """Get or initialize the fastest possible classifier."""
    global _classifier, _model_loading_time
    
    if not TRANSFORMERS_AVAILABLE:
        return None
    
    if _classifier is None:
        start_time = time.time()
        try:
            # Use DistilBERT for sentiment as a proxy for urgency/importance
            _classifier = pipeline(
                "text-classification",
                model="distilbert-base-uncased-finetuned-sst-2-english",
                device=-1,  # Force CPU to avoid CUDA issues
                top_k=2  # Get both positive and negative scores
            )
            _model_loading_time = time.time() - start_time
            logger.info(f"Loaded fast classifier in {_model_loading_time:.2f}s")
        except Exception as e:
            logger.error(f"Failed to load transformer: {e}")
            return None
    
    return _classifier


def enhanced_keyword_classification(text: str) -> Tuple[bool, float]:
    """
    Enhanced keyword-based classification.
    Significantly improved from the basic version.
    """
    text_lower = text.lower()
    
    # Primary disaster indicators (high confidence)
    primary_indicators = {
        "tsunami": 1.0, "cyclone": 1.0, "hurricane": 1.0, "earthquake": 0.9,
        "flood": 0.9, "flooding": 0.9, "evacuation": 0.8, "emergency": 0.7,
        "disaster": 0.8, "alert": 0.6, "warning": 0.6, "storm surge": 1.0,
        "landslide": 0.9, "avalanche": 0.9, "wildfire": 0.8, "drought": 0.7
    }
    
    # Secondary indicators (medium confidence)
    secondary_indicators = {
        "rainfall": 0.4, "weather": 0.3, "coastal": 0.3, "marine": 0.4,
        "forecast": 0.3, "monsoon": 0.4, "tide": 0.4, "wave": 0.3,
        "wind": 0.3, "storm": 0.5, "heavy rain": 0.5, "advisory": 0.4
    }
    
    # Geographic boosters (Indian context)
    geographic_boosters = {
        "india": 0.2, "indian": 0.2, "mumbai": 0.3, "delhi": 0.3, "chennai": 0.3,
        "kolkata": 0.3, "kerala": 0.3, "gujarat": 0.3, "odisha": 0.3, "bengal": 0.3,
        "maharashtra": 0.3, "karnataka": 0.3, "tamil nadu": 0.3, "coast": 0.3,
        "coastal": 0.3, "bay of bengal": 0.4, "arabian sea": 0.4
    }
    
    # Urgency amplifiers
    urgency_amplifiers = {
        "breaking": 0.3, "urgent": 0.3, "immediate": 0.4, "now": 0.2,
        "live": 0.3, "update": 0.2, "latest": 0.2, "developing": 0.3
    }
    
    # Calculate scores
    primary_score = 0
    for term, weight in primary_indicators.items():
        if term in text_lower:
            primary_score += weight
    
    secondary_score = 0
    for term, weight in secondary_indicators.items():
        if term in text_lower:
            secondary_score += weight
    
    geographic_score = 0
    for term, weight in geographic_boosters.items():
        if term in text_lower:
            geographic_score += weight
    
    urgency_score = 0
    for term, weight in urgency_amplifiers.items():
        if term in text_lower:
            urgency_score += weight
    
    # Enhanced scoring logic
    base_score = primary_score + secondary_score * 0.5
    boosted_score = base_score + geographic_score + urgency_score
    
    # Classification rules
    if primary_score >= 1.5:  # Multiple strong indicators
        confidence = min(0.95, 0.8 + boosted_score * 0.05)
        return True, confidence
    elif primary_score >= 0.8 and (geographic_score > 0 or urgency_score > 0):
        confidence = min(0.9, 0.7 + boosted_score * 0.05)
        return True, confidence
    elif boosted_score >= 1.2:  # Good combination of indicators
        confidence = min(0.8, 0.5 + boosted_score * 0.1)
        return True, confidence
    elif boosted_score >= 0.6:  # Some indication
        confidence = 0.3 + boosted_score * 0.1
        return confidence > 0.4, confidence
    else:
        return False, max(0.05, boosted_score * 0.1)


def hybrid_classification(text: str) -> Tuple[bool, float]:
    """
    Hybrid approach: Enhanced keywords + transformer sentiment.
    """
    # First get keyword-based classification
    keyword_relevant, keyword_confidence = enhanced_keyword_classification(text)
    
    # Try transformer enhancement
    classifier = get_fast_classifier()
    if classifier is None:
        return keyword_relevant, keyword_confidence
    
    try:
        # Truncate for speed
        text_truncated = text[:200] if len(text) > 200 else text
        
        # Get sentiment scores
        result = classifier(text_truncated)
        
        # Extract scores properly
        positive_score = 0.5  # Default
        for item in result:
            if item['label'] == 'POSITIVE':
                positive_score = item['score']
                break
        
        # Combine scores intelligently
        if keyword_relevant:
            # Keywords found disaster content, use high confidence
            # Transformer just provides minor adjustment
            final_confidence = min(0.95, keyword_confidence * 0.85 + positive_score * 0.15)
            return True, final_confidence
        else:
            # No keywords, be very conservative with transformer alone
            transformer_confidence = positive_score * 0.3
            return transformer_confidence > 0.25, max(keyword_confidence, transformer_confidence)
            
    except Exception as e:
        logger.debug(f"Transformer classification failed: {e}")
        return keyword_relevant, keyword_confidence


def classify_text_fast(text: str) -> Tuple[bool, float]:
    """
    Main fast classification function.
    
    Args:
        text (str): Text to classify
        
    Returns:
        tuple: (is_relevant: bool, confidence: float)
    """
    if not text or len(text.strip()) < 5:
        return False, 0.0
    
    # For very short texts, use keywords only (faster)
    if len(text) < 30:
        return enhanced_keyword_classification(text)
    
    # For longer texts, try hybrid approach
    return hybrid_classification(text)


def batch_classify_fast(texts: List[str]) -> List[Tuple[bool, float]]:
    """
    Fast batch classification.
    
    Args:
        texts: List of texts to classify
        
    Returns:
        List of (is_relevant, confidence) tuples
    """
    if not texts:
        return []
    
    start_time = time.time()
    results = []
    
    for text in texts:
        result = classify_text_fast(text)
        results.append(result)
    
    total_time = time.time() - start_time
    avg_time = total_time / len(texts)
    
    relevant_count = sum(1 for is_rel, _ in results if is_rel)
    logger.info(f"Classified {len(texts)} texts: {relevant_count} relevant, {avg_time:.3f}s avg")
    
    return results


# Compatibility function for existing pipeline
def is_relevant_enhanced(text: str) -> bool:
    """
    Enhanced version of is_relevant function for direct replacement.
    
    Args:
        text (str): Text to check
        
    Returns:
        bool: True if relevant to disasters
    """
    is_rel, confidence = classify_text_fast(text)
    return is_rel


if __name__ == "__main__":
    # Production speed test
    print("üöÄ Production-Ready Fast NLP Classifier Test")
    print("=" * 70)
    
    # Realistic test cases from actual scraper output
    real_world_tests = [
        "[INCOIS] UPDATE: Tsunami watch cancelled for Kerala, Karnataka coasts.",
        "üè¢ Earthquake Alert: M6.1 quake strikes Sikkim-Nepal border region.",
        "[Times of India] Cyclone Biparjoy: Gujarat evacuates 1 lakh people",
        "Summary: Comprehensive coverage of disaster management across India.",
        "[YouTube] Breaking news coverage of flood situation in Mumbai today",
        "Recipe: How to make perfect pasta with fresh tomato sauce",
        "Stock market analysis shows positive trends for technology sector",
        "[NDMA] Emergency preparedness drill conducted in coastal districts",
        "Weather forecast: Clear skies expected for weekend activities",
        "[Government] IMD issues heavy rainfall warning for next 48 hours"
    ]
    
    print(f"Testing {len(real_world_tests)} real-world examples:")
    print()
    
    # Individual timing test
    times = []
    results = []
    
    for i, text in enumerate(real_world_tests, 1):
        start = time.time()
        is_relevant, confidence = classify_text_fast(text)
        processing_time = time.time() - start
        times.append(processing_time)
        results.append((is_relevant, confidence))
        
        status = "‚úÖ RELEVANT" if is_relevant else "‚ùå NOT RELEVANT"
        print(f"{i:2d}. {status} ({confidence:.3f}) [{processing_time*1000:.1f}ms] - {text[:50]}...")
    
    # Summary statistics
    avg_time = sum(times) / len(times)
    max_time = max(times)
    min_time = min(times)
    relevant_count = sum(1 for is_rel, _ in results if is_rel)
    
    print()
    print("üìä PERFORMANCE SUMMARY:")
    print(f"  Average time: {avg_time*1000:.1f}ms per text")
    print(f"  Min/Max time: {min_time*1000:.1f}ms / {max_time*1000:.1f}ms")
    print(f"  Relevant texts: {relevant_count}/{len(real_world_tests)}")
    print(f"  Success rate: {relevant_count/len(real_world_tests)*100:.1f}%")
    
    print()
    print("üéØ PERFORMANCE TARGETS:")
    print(f"  Target: <100ms per text")
    print(f"  Achieved: {avg_time*1000:.1f}ms per text")
    
    if avg_time < 0.1:
        print("  ‚úÖ PERFORMANCE TARGET MET!")
    else:
        print("  ‚ùå Need optimization")
    
    # Test batch processing
    print(f"\nüì¶ BATCH PROCESSING TEST:")
    start_time = time.time()
    batch_results = batch_classify_fast(real_world_tests)
    batch_time = time.time() - start_time
    batch_avg = batch_time / len(real_world_tests)
    
    print(f"  Batch total time: {batch_time:.3f}s")
    print(f"  Batch average: {batch_avg*1000:.1f}ms per text")
    print(f"  Efficiency: {(avg_time/batch_avg):.1f}x faster than individual")
    
    print("\n" + "=" * 70)
    print("üéâ Ready for production integration!")